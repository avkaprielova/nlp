{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_nlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEhixidLHfFa",
        "colab_type": "text"
      },
      "source": [
        "# Проект по АвтОбрЕЯ\n",
        "\n",
        "Ccылка на файл с требованиями: https://docs.google.com/document/d/1hHPc2y_fXNvlh623_5GTAMqcAtSucxNaC9ZRuwHi3Wk/edit#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlbhlHB8IEV-",
        "colab_type": "text"
      },
      "source": [
        "### Над проектом работали:\n",
        "\n",
        "*   Андрей Зырянов\n",
        "*   Настя Каприелова\n",
        "*   Настя Кромина\n",
        "*   Петрова Даша"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJDWN-BBHoWX",
        "colab_type": "text"
      },
      "source": [
        "При выполнении задачи приветствуются эксперименты с теми методами, про которые рассказывали на занятиях: различные меры ассоциативной связи (коллокационные меры), разрешения семантической неоднозначности (AdaGram, семантическое расстояние по РуТез), определения семантической близости, тематическое моделирование, извлечение словаря тональной лексики…\n",
        "Для морфологической разметки и выделения синтаксических связей можно использовать UDPipe. Кроме того, можно использовать различные дополнительные ресурсы: векторные модели / эмбеддинги (в том числе мультиязычные), любые другие корпуса (например, описания блюд для составления списка блюд)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw6hK2nczIEb",
        "colab_type": "text"
      },
      "source": [
        "**Формируем датасет для корпуса SentiRuEval_rest_train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfGvxyBQTIS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1g7b8voPSg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99ac3fb6-e95f-4a01-d7fd-84ed4e4c8eed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sbx2CrTPne2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('gdrive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI_pJ-4zzFUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_train_file = open('SentiRuEval_rest_train.xml', 'r', encoding = 'utf-8', errors='ignore')\n",
        "corpus_train = corpus_train_file.read()\n",
        "corpus_train_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRoWr4jWQrl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = re.findall(r'<text>(.*?)</text>', corpus_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWkIRhZLTzw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "food = re.findall(r'<food>(.*?)</food>', corpus_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAPkbexmT_Kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "service = re.findall(r'<service>(.*?)</service>', corpus_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwodFO9ld_sB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = {'texts': texts, 'food': food, 'service': service}\n",
        "df = pd.DataFrame(data=d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwQvtG9Yr4Ij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "08adc603-ebd8-46eb-8de7-cb8c8cb83de7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texts</th>\n",
              "      <th>food</th>\n",
              "      <th>service</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>И пускай на меня не обижается наш прославленны...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>- Здравствуйте. Виа Д’Арженто! - Добрый вечер,...</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Советую вам уволить Вашего метродотеля Елену, ...</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>отличный средне вековый интеръер. Приятное обс...</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ужинали в ресторане Баден-Баден 6 марта . Импо...</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               texts food service\n",
              "0  И пускай на меня не обижается наш прославленны...    8       8\n",
              "1  - Здравствуйте. Виа Д’Арженто! - Добрый вечер,...    9      10\n",
              "2  Советую вам уволить Вашего метродотеля Елену, ...    9       1\n",
              "3  отличный средне вековый интеръер. Приятное обс...    8       9\n",
              "4  Ужинали в ресторане Баден-Баден 6 марта . Импо...   10       8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIG7u4taJeAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "5719c93e-715e-449a-eb76-3ac5fb349326"
      },
      "source": [
        "!pip install pymorphy2"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (2.4.393442.3710985)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.7.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJNxhmoMLJ0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocessing texts in the df\n",
        "import pymorphy2\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "\n",
        "p = re.compile(r'[\\W^ ]')\n",
        "morph = pymorphy2.MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zrOtsxYbXVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "updated_texts = []\n",
        "for row in df['texts'][:5000]:\n",
        "  clean = p.sub(' ', row)\n",
        "  words = clean.split()\n",
        "  new_text = ' '.join(words)\n",
        "  updated_texts.append(new_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aHo9CV5dP90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(text):\n",
        "    tokens = tokenizer.tokenize(text.lower())\n",
        "    lemmas = [morph.parse(t)[0].normal_form for t in tokens]\n",
        "    return lemmas\n",
        "\n",
        "\n",
        "def get_ngrams(tokens, n, patterns=None):\n",
        "    ngrams = []\n",
        "    for i in range(len(tokens) - (n - 1)):\n",
        "        ngram = tokens[i:i+n]\n",
        "        tags = [morph.parse(t)[0].tag.POS for t in ngram]\n",
        "        if patterns is not None:\n",
        "            if tags in patterns:\n",
        "                ngrams.append(ngram)\n",
        "        else:\n",
        "            ngrams.append(ngram)\n",
        "    return ngrams"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vx-bBKiiAV5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUW2HZjneUze",
        "colab_type": "text"
      },
      "source": [
        "Создадим списки с биграммами и триграммами для проверки сочетаемости слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIL_YD4kdhR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e244c60-e904-4302-b366-784af256de55"
      },
      "source": [
        "start_time = time.time()\n",
        "all_bigrams_adj = []\n",
        "for text in updated_texts: \n",
        "  bi_grams = get_ngrams(normalize(text), n=2, patterns=[['ADJF', 'NOUN']])\n",
        "  all_bigrams_adj.append(bi_grams)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- 476.0370469093323 seconds ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzxT-7fFfcyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_time = time.time()\n",
        "all_trigrams_adv_adj = []\n",
        "for text in updated_texts: \n",
        "  tr_grams_adv_adj = get_ngrams(normalize(text), n=3, patterns=[['ADVB', 'ADJF', 'NOUN']])\n",
        "  all_trigrams_adv_adj.append(tr_grams_adv_adj)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPPoLW0RghUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_time = time.time()\n",
        "all_trigrams_adv_verb = []\n",
        "for text in updated_texts: \n",
        "  tr_grams_adv_verb = get_ngrams(normalize(text), n=3, patterns=[['NOUN', 'ADVB', 'INFN']])\n",
        "  all_trigrams_adv_verb.append(tr_grams_adv_verb)\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI_Y7pjY6pRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#достаем из данных нам списков слова, которые можно отнести к Food 0, Food 1, Service 0 или Service 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMw-3mZY-EYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Food_file = open('Food_words.txt', 'r', encoding = 'utf-8')\n",
        "Food = Food_file.read()\n",
        "Food_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAb6i4KD_R7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Food_split = Food.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtXmGoc-Ba8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Food0 = []\n",
        "Food1 = []\n",
        "for i in Food_split:\n",
        "  r = i.split('        ')\n",
        "  if r[2] == '1':\n",
        "    Food1.append(r[1])\n",
        "  if r[2] == '0':\n",
        "    Food0.append(r[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qqjh3cpDftV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Service_file = open('Service_words.txt', 'r', encoding = 'utf-8')\n",
        "Service = Service_file.read()\n",
        "Service_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bz88CWxsEYeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Service_split = Service.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlPud101D04D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Service0 = []\n",
        "Service1 = []\n",
        "for i in Service_split:\n",
        "  r1 = i.split('\\t')\n",
        "  if r1[2] == '1':\n",
        "    Service1.append(r1[1])\n",
        "  if r1[2] == '0':\n",
        "    Service0.append(r1[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6WLmorJRIaI",
        "colab_type": "text"
      },
      "source": [
        "Загрузим модель, чтобы использовать её эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN9BieYeRETe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "\n",
        "from gensim.models import Word2Vec, KeyedVectors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm2LgVaKRZGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "import re\n",
        "def tokenize(line): #функция возвращает список токенов данного предложения\n",
        "  ws = []\n",
        "  words = line.split()\n",
        "  for w in words:\n",
        "    w = re.sub('[.,-;:?!@#$%^&()_+=—–\"…}{/\\|«»>]', '', w).lower()\n",
        "    if w != \"\":\n",
        "      p = morph.parse(w)[0]\n",
        "      ws.append(p.normal_form)\n",
        "  return ws"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REMzfLD_RfPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cossim(v1,v2): # функция подсчета косинусного расстояния\n",
        "  return dot(v1, v2)/(norm(v1)*norm(v2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt9SHwX6RpPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3dbb2483-2692-4cc4-8e4e-d915ad14833d"
      },
      "source": [
        "model_file = 'model.model'\n",
        "model = KeyedVectors.load(model_file)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq2XIq5LR1Uw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "029484ad-5b96-4ff1-dbfb-9411500eb07b"
      },
      "source": [
        "query = 'Картошка была прекрасна.'\n",
        "query_tok = tokenize(query)\n",
        "query_tok"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['картошка', 'быть', 'прекрасный']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKCGuw55R8Iu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "f75c1fb2-0c83-4495-c3d7-40e268f6f846"
      },
      "source": [
        "query_vec = []\n",
        "for i in query_tok:\n",
        "  res = i in model.wv\n",
        "  print(i, ': ', res)\n",
        "  print(model[i][:5])\n",
        "  query_vec.append(model[i])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "картошка :  True\n",
            "[-0.01691983 -0.5142729   0.31042105  0.5475326  -0.28163046]\n",
            "быть :  True\n",
            "[ 0.1256133  -0.54293644  0.24227035  0.04432327  0.1083925 ]\n",
            "прекрасный :  True\n",
            "[ 0.12641275 -0.31853437  0.04751264 -0.06571354  0.1707755 ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzfwSLh4UeIw",
        "colab_type": "text"
      },
      "source": [
        "Создадим дополнительные сиды, а также сделаем массивы их векторов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y3mwyDqRt_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_food = ['мясо','рыба','лук','гриб', 'помидор']\n",
        "food_vec = []\n",
        "for i in seed_food:\n",
        "  food_vec.append(model[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApaFJQwlSGtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_serv = ['официант','обслуживание','сервис','администратор', 'сотрудник']\n",
        "serv_vec = []\n",
        "for i in seed_serv:\n",
        "  serv_vec.append(model[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E5LAhZgTT3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "92ded69a-c182-4c12-d71a-794c5f56216e"
      },
      "source": [
        "for i in range(len(query_vec)):\n",
        "  total = 0\n",
        "  v1 = query_vec[i]\n",
        "  for j in range(len(food_vec)):\n",
        "    v2 = food_vec[j]\n",
        "    sim = cossim(v1,v2)\n",
        "    total += sim\n",
        "  print(f'Близость слова \"{query_tok[i]}\" к food_seed = {total}')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Близость слова \"картошка\" к food_seed = 2.6930912733078003\n",
            "Близость слова \"быть\" к food_seed = 1.044472575187683\n",
            "Близость слова \"прекрасный\" к food_seed = 0.7706841230392456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q8wVSLYTerl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_pos = []\n",
        "for i in Food1:\n",
        "  seed_pos.append(i)\n",
        "for i in Service1:\n",
        "  seed_pos.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oYAW33ETwgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f3f0aac-af70-4fda-a16a-e7a4358e4af8"
      },
      "source": [
        "len(seed_pos)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLJ6rzPQWpLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_pos = ['отличный','вкусный','сочный','удобный']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EMLbi7STbRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_vec = []\n",
        "for i in seed_pos:\n",
        "  pos_vec.append(model[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7netenpoT8D1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_neg = []\n",
        "for i in Food0:\n",
        "  seed_neg.append(i)\n",
        "for i in Service0:\n",
        "  seed_neg.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpJHmywsUOY6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9df320cb-b7b5-46bc-c968-488b45095dfe"
      },
      "source": [
        "len(seed_neg)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMlF_2LsWxW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_neg = ['ужасный','кошмарный','отвратительный','злой']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrTFjvZiUQ7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "neg_vec = []\n",
        "for i in seed_neg:\n",
        "  neg_vec.append(model[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFJbMSDXUmrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#кандидаты по близости\n",
        "food_cand = []\n",
        "serv_cand = []\n",
        "pos_cand = []\n",
        "neg_cand = []\n",
        "\n",
        "#их вектора\n",
        "food_vec_cand = []\n",
        "serv_vec_cand = []\n",
        "pos_vec_cand = []\n",
        "neg_vec_cand = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsCD2blKVPjV",
        "colab_type": "text"
      },
      "source": [
        "Функция detect находит в предложениии кандидатов для пополнения списков seed и выдает результат в соответствующем формате\n",
        "\n",
        "Для задачи нахождения оценочных слов с каким-то аспектом в предложении, формат вывода отличается, поэтому для его переформатирования используется функция  result_transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm5EYG83VTDQ",
        "colab_type": "text"
      },
      "source": [
        "В функции detect мы для каждого слова из предложения смотрим его косинуную близость со словами из сидов, если число близостей, которые > 0.3, превышает 75% от сида, добавляем слово в кандидаты для пополнения сида.\n",
        "\n",
        "Если в одном предложении встречается слово с аспектом и оценочное слово, пара становится кандидатом для списка оценочных слов.\n",
        "\n",
        "Все кандидаты далее будут проверяться на основе сравнения с коллокациями."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjZU77NjUrVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "1de0a22f-6c40-482e-8012-a380edc5c2fa"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48lccJN7U6yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords = set(stopwords.words('russian'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RVpDrApiUQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "candidates = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqmtjy43U8o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def detect(sent): # для одного предложения\n",
        "  result = []\n",
        "  old_food_len = len(food_cand)\n",
        "  old_serv_len = len(serv_cand)\n",
        "  old_pos_len = len(pos_cand)\n",
        "  old_neg_len = len(neg_cand)\n",
        "\n",
        "  words = tokenize(sent)\n",
        "  food = 'no food'\n",
        "  service = 'no service'\n",
        "\n",
        "  for i in range(len(words)):\n",
        "    if words[i] not in stopwords:\n",
        "      sim_pass = 0\n",
        "      for j in food_vec:  #цикл для еды\n",
        "        sim = cossim(model[words[i]], j)\n",
        "        if sim > 0.3:\n",
        "          sim_pass += 1\n",
        "      if sim_pass > 3:\n",
        "        food = 'detected'\n",
        "        if words[i] not in food_cand: \n",
        "          food_cand.append(words[i])\n",
        "          food_vec_cand.append(model[words[i]])\n",
        "      new_food_len = len(food_cand)\n",
        "\n",
        "      sim_pass_serv = 0\n",
        "      for s in serv_vec: #цикл для сервиса\n",
        "        sim = cossim(model[words[i]], s)\n",
        "        if sim > 0.3:\n",
        "          sim_pass_serv += 1\n",
        "      if sim_pass_serv > 3:\n",
        "        service = 'detected'\n",
        "        if words[i] not in serv_cand: \n",
        "          serv_cand.append(words[i])\n",
        "          serv_vec_cand.append(model[words[i]])\n",
        "      new_serv_len = len(serv_cand)\n",
        "\n",
        "      sim_pass_pos = 0  \n",
        "      for p in pos_vec: #цикл для положительных слов\n",
        "        sim = cossim(model[words[i]], p)\n",
        "        if sim > 0.3:\n",
        "          sim_pass_pos += 1\n",
        "      if sim_pass_pos > 3 and words[i] not in pos_cand: \n",
        "        pos_cand.append(words[i])\n",
        "        pos_vec_cand.append(model[words[i]])\n",
        "      new_pos_len = len(pos_cand)\n",
        "\n",
        "      sim_pass_neg = 0\n",
        "      for n in neg_vec: #цикл для негативных слов\n",
        "        sim = cossim(model[words[i]], n)\n",
        "        if sim > 0.3:\n",
        "          sim_pass_neg += 1\n",
        "      if sim_pass_neg > 3 and words[i] not in neg_cand: \n",
        "        neg_cand.append(words[i])\n",
        "        neg_vec_cand.append(model[words[i]])\n",
        "      new_neg_len = len(neg_cand)\n",
        "\n",
        "  if food == 'detected' and service == 'no service': # если есть еда, но нет сервиса\n",
        "    if old_pos_len != new_pos_len: # если новое положительное слово\n",
        "      result.append(f'Food\\t{words[i]}\\t1')\n",
        "      candidates.append(f'Food\\t{words[i]}\\t1')\n",
        "    elif old_neg_len != new_neg_len: # если новое отрицательное слово\n",
        "      result.append(f'Food\\t{words[i]}\\t0')\n",
        "      candidates.append(f'Food\\t{words[i]}\\t0')\n",
        "\n",
        "  if service == 'detected' and food == 'no food': # если есть сервис, но нет еды\n",
        "    if old_pos_len != new_pos_len: # если новое положительное слово\n",
        "      result.append(f'Service\\t{words[i]}\\t1')\n",
        "      candidates.append(f'Service\\t{words[i]}\\t1')\n",
        "    elif old_neg_len != new_neg_len: # если новое отрицательное слово\n",
        "      result.append(f'Service\\t{words[i]}\\t0')\n",
        "      candidates.append(f'Service\\t{words[i]}\\t0')\n",
        "      \n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJDE8NhXVCqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_tt = 'Официантка была грубой.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOWJnDGuVLMc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ead1460-0f63-47f4-e91d-e6d4351c8e56"
      },
      "source": [
        "detect(sent_tt)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Service\\tгрубый\\t0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuzeSQa7VZVn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d321e89e-fd82-4ea0-80cc-e4861ba0fd04"
      },
      "source": [
        "print(food_cand)\n",
        "print(serv_cand)\n",
        "print(pos_cand)\n",
        "print(neg_cand)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "['официантка']\n",
            "[]\n",
            "['грубый']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj2ZGinVXN0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_test(text): #detect для текста\n",
        "  sents = []\n",
        "  pattern = re.compile(r'([А-ЯA-Z]((т.п.|т.д.|пр.|г.)|[^?!.\\(]|\\([^\\)]*\\))*[.?!]*)')\n",
        "  for i,sent in enumerate(pattern.findall(text)):\n",
        "    sents.append(sent[0])\n",
        "  res = [] # результаты по всем предложениям текста\n",
        "  for i in sents:\n",
        "    result = detect(i)\n",
        "    if result != []:\n",
        "      #new_form = result_transform(result):\n",
        "      #res.append(new_form)\n",
        "      res.append(result)\n",
        "  \n",
        "  return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBc9Itc_XecZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a093fae-ef6c-4f28-9b6e-7f7ab3d2b468"
      },
      "source": [
        "test_text = 'Еда была очень вкусной. Официантка была злой и грубой!'\n",
        "test_res = text_test(text)\n",
        "test_res"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Food\\tвкусный\\t1'], ['Service\\tгрубый\\t0']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMVsUSSfh0-8",
        "colab_type": "text"
      },
      "source": [
        "После обработки 1000 текстов, мы нашли следующих кандидатов для списков слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk40rIVohwXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "47b90e24-ec26-475e-97d5-18a076bd741a"
      },
      "source": [
        "print(food_cand)\n",
        "print(serv_cand)\n",
        "print(pos_cand)\n",
        "print(neg_cand)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['еда', 'вкусный', 'поесть', 'вкусно', 'мясо', 'кондитерский', 'мясной', 'запеканка', 'паста', 'говядина', 'пицца', 'тесто', 'креветка', 'макрель', 'пиво', 'поедать', 'фрукт', 'сервировка', 'шампанский', 'рыба', 'кролик', 'белуга', 'сакура', 'каштан', 'десерт', 'блюдо', 'пиццерия', 'харчо', 'невкусно', 'полуфабрикат', 'закуска', 'казалось', 'жареный', 'молодая', 'осьминог', 'шоколадный', 'съесть', 'сало', 'клешня', 'пельмень', 'колбаска', 'баранина', 'баклажан', 'торт', 'мороженое']\n",
            "['официантка', 'обслуживание', 'ресторан', 'заведение', 'клиент', 'кондитерский', 'комендантский', 'администратор', 'сотрудник', 'организация', 'банкетный', 'заказ', 'парковский', 'ресторанчик', 'кафешка', 'посетитель', 'персонал', 'оператор', 'автосалон', 'интерьер', 'сервис', 'ресторанный', 'официант', 'работник', 'работодатель', 'зарплата', 'обслуживаться', 'корпоративный', 'пиццерия', 'турист']\n",
            "['вкусный', 'красивый', 'оригинальный', 'шикарный', 'приятный', 'пристойный', 'симпатичный', 'привлекательный', 'стильный', 'добротный', 'роскошный']\n",
            "['злой', 'грубый', 'отвратительный', 'ужасный', 'неприятный', 'откровенный', 'странный', 'обидный', 'нескучный', 'отвратный', 'хамский', 'тоска', 'безобразно']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFFtCAnfYl9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ress = []\n",
        "for i in texts[:2000]:\n",
        "  try:\n",
        "    ress.append(text_test(i))\n",
        "  except AttributeError:\n",
        "    continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwlybL47i9Gf",
        "colab_type": "text"
      },
      "source": [
        "После 2000 пополнили еще."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKWZkYRfi2q-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "d8fa859f-17dc-484f-de71-5adf260afb9b"
      },
      "source": [
        "print(food_cand)\n",
        "print(serv_cand)\n",
        "print(pos_cand)\n",
        "print(neg_cand)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['еда', 'вкусный', 'поесть', 'вкусно', 'мясо', 'кондитерский', 'мясной', 'запеканка', 'паста', 'говядина', 'пицца', 'тесто', 'креветка', 'макрель', 'пиво', 'поедать', 'фрукт', 'сервировка', 'шампанский', 'рыба', 'кролик', 'белуга', 'сакура', 'каштан', 'десерт', 'блюдо', 'пиццерия', 'харчо', 'невкусно', 'полуфабрикат', 'закуска', 'казалось', 'жареный', 'молодая', 'осьминог', 'шоколадный', 'съесть', 'сало', 'клешня', 'пельмень', 'колбаска', 'баранина', 'баклажан', 'торт', 'мороженое', 'блин', 'салат', 'поварить', 'жаркое', 'птица', 'капуста', 'морс', 'столовый', 'клюква', 'мамалыга', 'пирожное', 'пирог', 'рыбный', 'мидия', 'корзиночка', 'малина', 'сливка', 'водка', 'кишмиш', 'шашлык', 'отведать', 'гюльчатай', 'вино', 'продукт', 'ложка', 'яйцо', 'овощной', 'сардина', 'стейк', 'телятина', 'имбирь', 'фасоль', 'кабачок', 'брынза', 'пётр', 'артишок', 'сыр']\n",
            "['официантка', 'обслуживание', 'ресторан', 'заведение', 'клиент', 'кондитерский', 'комендантский', 'администратор', 'сотрудник', 'организация', 'банкетный', 'заказ', 'парковский', 'ресторанчик', 'кафешка', 'посетитель', 'персонал', 'оператор', 'автосалон', 'интерьер', 'сервис', 'ресторанный', 'официант', 'работник', 'работодатель', 'зарплата', 'обслуживаться', 'корпоративный', 'пиццерия', 'турист', 'казино', 'офис', 'обслуживающий', 'обходительный', 'владелец', 'бизнес', 'обслуживать', 'выпускник', 'метрдотель', 'метрополь', 'респектабельный', 'стажер', 'отель']\n",
            "['вкусный', 'красивый', 'оригинальный', 'шикарный', 'приятный', 'пристойный', 'симпатичный', 'привлекательный', 'стильный', 'добротный', 'роскошный', 'прикольный', 'качественный', 'ладный', 'респектабельный']\n",
            "['злой', 'грубый', 'отвратительный', 'ужасный', 'неприятный', 'откровенный', 'странный', 'обидный', 'нескучный', 'отвратный', 'хамский', 'тоска', 'безобразно', 'извратить', 'бестолковый', 'адский', 'двойственный', 'пошлый', 'страдание', 'ужасно', 'пренеприятный', 'счастливый', 'навязчивый', 'забавный', 'дикий', 'нестыдный', 'голодный', 'дождливый', 'неспокойный']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx9jKsA6jFgp",
        "colab_type": "text"
      },
      "source": [
        "Видно, что цикл для пар очень строгий и они почти не находятся. Поэтому мы решили при помощи исследования коллокаций и расширенных сидов определять аспекты для выделенных кандидатов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH2QgtZgYovU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b9b3a47-00c6-4367-f98a-aa1ad51e8917"
      },
      "source": [
        "candidates"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Service\\tолимпий\\t0', 'Service\\tпаб\\t1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9ZN_m-Cf4dW",
        "colab_type": "text"
      },
      "source": [
        "Ниже функция, которая использует распарсенные udpipe данные, чтобы находить токен нужного слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohtsC_ntfsTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "with open('sentences_parsed', 'r', encoding = 'utf-8') as f:\n",
        "    parsed = f.read()\n",
        "    texts = parsed.split('SpacesAfter=\\\\r\\\\n')\n",
        "    reviews = []\n",
        "    for text in texts:\n",
        "        sentences_raw = text.split('# sent_id')\n",
        "        sentences = []\n",
        "        for sent_raw in sentences_raw[1:]:\n",
        "            words = sent_raw.split('\\n')[2:]\n",
        "            sentences.append(words)\n",
        "        reviews.append(sentences)\n",
        "\n",
        "def searchsent(i_rev, i_sent, word):\n",
        "    i_out = []\n",
        "    lemma = normalize(word)[0]\n",
        "    for line in reviews[i_rev][i_sent]:\n",
        "        if re.findall(lemma, line) != []:\n",
        "            i_out.append(line.split('\\t')[0])\n",
        "    return i_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEiI4zyHZ5AK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fd174f1b-1ffc-4375-f5b8-a19be449590b"
      },
      "source": [
        "\n",
        "#def result_transform(result): #функция, которая меняет формат выходных данных функции detect в соответствии с заданием\n",
        "  \n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Food\\tвкусный\\t1']\n",
            "['Service\\tгрубый\\t0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHh0n06thGu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}